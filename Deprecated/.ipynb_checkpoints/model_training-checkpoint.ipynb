{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0576cb8d-096e-4877-a266-6c457ebf2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "import json\n",
    "import import_ipynb\n",
    "import ipywidgets as widgets\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ASL\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "### pretty print = off\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eea02-d086-4c74-a449-8c6521d03aa6",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45a9ec94-f307-4e23-919d-8f271befc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta = ASL.metadata('train')\n",
    "MetaS = ASL.metadata('supplemental')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a16cb-6469-4550-bbf2-e1f4d5182478",
   "metadata": {},
   "source": [
    "## Selecting datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbb29c9-6dca-4d7c-a554-c9fb12353b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ASL.str(MetaS.files[1])\n",
    "Datafile = ASL.datafile(MetaS, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56aed9c-6200-453e-9b78-5715e2f985c8",
   "metadata": {},
   "source": [
    "## Selecting videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4edec-cb39-4801-b1b6-0a2ed24411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = Datafile.videos[i]\n",
    "W = video(Datafile, vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c99349-dffb-40e3-be98-e278bd3903bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = show_hands(W)\n",
    "interact(f, frame=widgets.IntSlider(min=0, max=len(W.handframes)-1, step=1, value=0, layout=widgets.Layout(width='1000px')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4facd273-2b92-417f-942b-4a7463aa48c1",
   "metadata": {},
   "source": [
    "# Label and Pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee59c0a-ff0d-4165-b33c-6b7a19e1a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label(V,M)\n",
    "\n",
    "# change label\n",
    "def changelabel(self, i, letter):\n",
    "    self.data_labels[i] = letter\n",
    "    \n",
    "# pickle function\n",
    "def pickle(D,V):\n",
    "    seq_id = str(V.id)\n",
    "    Frames = V.frames\n",
    "    D[seq_id] = V.data_labels\n",
    "    \n",
    "#for i in range(81,82):\n",
    "    #changelabel(V,i,'?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec78a9f-b71c-418b-a2d4-7ebd919c4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(81,82):\n",
    "    #changelabel(V,i,'?')\n",
    "# pickle(D,V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f2f19-1161-4ed4-bc38-03fc3bd15cc8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323762b6-df28-4b10-be69-4f1f51b18df5",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c4c21-3b6e-4261-8064-277032e4f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "X, y = [], []\n",
    "\n",
    "# loop over file ids\n",
    "def generate_training_data(file):\n",
    "    \n",
    "    # load dictionary\n",
    "    dstring = 'Labels/Labels' + str(file) + '.json'\n",
    "    with open( dstring, 'r') as f:\n",
    "        train = json.load(f)\n",
    "    \n",
    "    Met = MetaS if file in MetaS.files else Meta\n",
    "    \n",
    "    for file in train:\n",
    "        # create datafile\n",
    "        Df = datafile(Met, file)\n",
    "        videos = train[file]\n",
    "        for vid in videos:\n",
    "        \n",
    "            # load date\n",
    "            V = video(Df, int(vid))\n",
    "            # N = normal_hand(V)\n",
    "            # pN = videos[vid]\n",
    "        \n",
    "            # loop\n",
    "            # for i in range(len(N)):\n",
    "                # if pN[i] != '?':\n",
    "                    # X.append( N[i] )\n",
    "                    #y.append( Encode( pN[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14d6af-e241-4a01-80b9-d0d943e38b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '86446671'\n",
    "dstring = 'Labels/Labels' + str(file) + '.json'\n",
    "with open( dstring, 'r') as f:\n",
    "    train = json.load(f)\n",
    "Met = MetaS\n",
    "Df = datafile(Met, file)\n",
    "videos = train[file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bb2b5-80e1-46e9-9a47-6f02d36f9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_files = [105143404, 128822441, 33432165, 86446671]\n",
    "training_files = [ 86446671, 33432165 ]\n",
    "for file in training_files:\n",
    "    generate_training_data(training_files)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57084ae-5c52-4e2e-8fac-86b48fb192c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ba0a5-82b3-43ec-8fb2-6722a39be580",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bc04b-f816-4d76-b074-74c3e8ea421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "k = 59\n",
    "M = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(20, 3)),\n",
    "    tf.keras.layers.Dense(6*k, activation='relu'),\n",
    "    tf.keras.layers.Dense(k)])\n",
    "\n",
    "# Compile Model\n",
    "M.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f4816-f96a-4643-be63-0fb895bf03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "# M.fit( X, y, epochs = 400, verbose=0 )\n",
    "# M.fit( X_train, y_train, epochs = 500, verbose=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee1667-c2af-4f70-83cd-b6769c7a1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, Acctrain = M.evaluate(X, y, verbose=2)\n",
    "# print('accuracy:', Acctrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73f942-0b7d-4ada-9940-d2e5ac910065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss, Acctrain = M.evaluate(X_train, y_train, verbose=2)\n",
    "#Loss, Acctest = M.evaluate(X_test, y_test, verbose=2)\n",
    "#print('\\nTrain accuracy:', Acctrain)\n",
    "#print('\\nTest accuracy:', Acctest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03903124-f656-4974-bc98-723cc4cbd5a5",
   "metadata": {},
   "source": [
    " ### save + load past models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c429df-a682-477f-a3b3-10be85822346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "# M.save(\"alphabetmodel.h5\")\n",
    "\n",
    "# load model \n",
    "M = tf.keras.models.load_model('alphabetmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7d0ba-d2a6-4861-875d-76ddc370d870",
   "metadata": {},
   "source": [
    "# External videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da09d8-35d8-43d7-8bcb-406c6ad582c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Samples/IMG_0970.MOV'\n",
    "V = video_file(path)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79274a17-b805-44da-a527-b0c0719a11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = show_annotated_video(V)\n",
    "interact(f, i=widgets.IntSlider(min=0, max=len(V.frames)-1, step=1, value=0, layout=widgets.Layout(width='1000px')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e90037-08fb-4f64-90e1-ee862f580917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrolling through image frames\n",
    "def hands(V):    \n",
    "    \n",
    "    # initialize\n",
    "    frames = V.hand_frames\n",
    "    annotated_image = np.zeros((1024,1024,3),dtype=np.uint8)\n",
    "       \n",
    "    # show function\n",
    "    def show_frame(frame):\n",
    "        # Only do frames with dominant hand\n",
    "        Hframe = frames[frame][0]\n",
    "\n",
    "        # Get landmark data\n",
    "        landmarks = blank()\n",
    "        \n",
    "        # set right hand to normalized hand\n",
    "        obj = landmark_pb2.LandmarkList()\n",
    "        obj.landmark.add( x=0., y=0., z=0. ) \n",
    "        for v in Hframe:\n",
    "            obj.landmark.add( x=v[0], y=v[1], z=v[2] ) \n",
    "        landmarks.right_hand_landmarks = shift( obj, np.array([.6,.7,0] ) )\n",
    "        \n",
    "        # show image \n",
    "        show_image( draw_landmarks(landmarks,annotated_image), figsize=(6,6), title=f'frame [{frame} of {len(frames)-1}]') # Prediction {predict(V,M,frame)} \n",
    "        #show_image(draw_landmarks(landmarks,annotated_image),figsize=(6,6),title=f'frame [{frame+1} of {len(frames)}] {phrase:50} phrase: { V.phrase }')\n",
    "        # print(f'showing frame: {frames[frame]}') # predict(V,frame)\n",
    "    \n",
    "    return show_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59075da-58e7-467d-8911-8c52d5a3f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hframe = V.hand_frames[0][0]\n",
    "landmarks = blank()\n",
    "obj = landmark_pb2.LandmarkList()\n",
    "obj.landmark.add( x=0., y=0., z=0. ) \n",
    "for v in Hframe:\n",
    "    obj.landmark.add( x=v[0], y=v[1], z=v[2] ) \n",
    "landmarks.right_hand_landmarks = shift( obj, np.array([.6,.7,0] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f470e-eb1d-45e6-b27f-882063881e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = hands(V)\n",
    "interact(f, frame=widgets.IntSlider(min=0, max=len(V.frames)-1, step=1, value=0, layout=widgets.Layout(width='1000px')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a380ed-b1cc-4728-b61f-cdee3a0d890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: current only has right hand\n",
    "def process_video(self):\n",
    "    \n",
    "    # rescale \n",
    "    m, n = self.resolution\n",
    "    # A = np.diag([ 950/m, 650/n , 1. ])\n",
    "    \n",
    "\n",
    "    L = []\n",
    "    for frame in self.landmarks:\n",
    "        if frame.hand_landmarks:\n",
    "            \n",
    "            # create the landmark\n",
    "            x = landmark_pb2.NormalizedLandmarkList()\n",
    "            # x = landmark_pb2.LandmarkList()\n",
    "            for v in frame.hand_landmarks[0]:\n",
    "                v = np.array([v.x, v.y, v.z])\n",
    "                # v = np.matrix([v.x, v.y, v.z]) # make vector\n",
    "                # v = np.array(v @ A)[0] # scale\n",
    "                x.landmark.add( x=v[0], y=v[1], z=v[2] ) \n",
    "            \n",
    "            # center the landmark\n",
    "            # x = shift(x, np.array([0., 0., 0. ]))\n",
    "            x = center(x)\n",
    "            \n",
    "            # extract the data \n",
    "            data = np.array([ [ Landmark_vector(x,i) for i in range(1,21) ] ])\n",
    "            \n",
    "            # add to L\n",
    "            L += [ data ]\n",
    "        else:\n",
    "            L += [ np.array([ [ np.array([0.,0.,0.]) for i in range(20) ] ]) ]   \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59be6b-6912-4289-a717-316f16af0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(V)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04acf40-1beb-4384-a08f-b4d55f249482",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(V)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21eb662-24e6-4e74-b98e-24e563857486",
   "metadata": {},
   "outputs": [],
   "source": [
    "V.hand_data = process_video(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2fcc5-6c11-4162-bbab-7a07a2909f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predictions\n",
    "def predict(self, M, frame):\n",
    "            \n",
    "    # data\n",
    "    data = self.hand_frames\n",
    "    data = np.array( data[frame] )\n",
    "    \n",
    "    # individual prediction\n",
    "    X = tf.keras.Sequential([ M, tf.keras.layers.Softmax() ])\n",
    "    p = X.predict(data, verbose=0)\n",
    "    \n",
    "    # prediction (encoded as an integer)\n",
    "    pred = np.argmax(p)\n",
    "    \n",
    "    # answer\n",
    "    ans = Decode(pred)\n",
    "              \n",
    "    # return\n",
    "    return ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd9a2a-d52e-4fbc-9c79-263abe15e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(normal_hand_data(W)[0][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307efb09-f770-41d7-9cdf-b4b90e979452",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = V.hand_frames[292]\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98228bd3-6fbf-40de-9dce-01b444cbf4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c6bae-470e-408c-af31-85336348740c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ec4cb-18cc-494a-a33f-7e965c34ee9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccf725-6be4-4fed-9bb4-4bbdfb028c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c65bd9-6fd8-4d39-b154-aab77675b3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195cb7d-df23-40ce-9916-55629a346c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
