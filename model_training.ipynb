{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0576cb8d-096e-4877-a266-6c457ebf2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import asl\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "### pretty print = off\n",
    "# %pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eea02-d086-4c74-a449-8c6521d03aa6",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a9ec94-f307-4e23-919d-8f271befc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta = asl.metadata('train')\n",
    "MetaS = asl.metadata('supplemental')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a16cb-6469-4550-bbf2-e1f4d5182478",
   "metadata": {},
   "source": [
    "## Selecting datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbb29c9-6dca-4d7c-a554-c9fb12353b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = str(MetaS.files[1])\n",
    "Datafile = asl.datafile(MetaS, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56aed9c-6200-453e-9b78-5715e2f985c8",
   "metadata": {},
   "source": [
    "## Selecting videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d4edec-cb39-4801-b1b6-0a2ed24411ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 10:41:21.899659: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "vid = Datafile.videos[0]\n",
    "W = asl.video(Datafile, vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c99349-dffb-40e3-be98-e278bd3903bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b427df02b0294951859765afcde23cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame', layout=Layout(width='1000px'), max=168), Output(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function asl.video.show_hands.<locals>.show_frame(frame)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = asl.show_hands(W)\n",
    "interact(f, frame=widgets.IntSlider(min=0, max=len(W.hand)-1, step=1, value=0, layout=widgets.Layout(width='1000px')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4facd273-2b92-417f-942b-4a7463aa48c1",
   "metadata": {},
   "source": [
    "# Label and Pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee59c0a-ff0d-4165-b33c-6b7a19e1a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label(V,M)\n",
    "\n",
    "# change label\n",
    "def changelabel(self, i, letter):\n",
    "    self.data_labels[i] = letter\n",
    "    \n",
    "# pickle function\n",
    "def pickle(D,V):\n",
    "    seq_id = str(V.id)\n",
    "    Frames = V.frames\n",
    "    D[seq_id] = V.data_labels\n",
    "    \n",
    "#for i in range(81,82):\n",
    "    #changelabel(V,i,'?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec78a9f-b71c-418b-a2d4-7ebd919c4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(81,82):\n",
    "    #changelabel(V,i,'?')\n",
    "# pickle(D,V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f2f19-1161-4ed4-bc38-03fc3bd15cc8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323762b6-df28-4b10-be69-4f1f51b18df5",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4c4c21-3b6e-4261-8064-277032e4f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "X, y = [], []\n",
    "\n",
    "# loop over file ids\n",
    "def generate_training_data(file):\n",
    "    \n",
    "    # file as string\n",
    "    sfile = str(file)\n",
    "    \n",
    "    # load dictionary\n",
    "    dstring = 'asl/Labels/Labels' + sfile + '.json'\n",
    "    with open( dstring, 'r') as f:\n",
    "        train = json.load(f)\n",
    "    \n",
    "    # select parameters \n",
    "    Met = MetaS if file in MetaS.files else Meta\n",
    "    Df = asl.datafile(Met, sfile )\n",
    "    videos = train[sfile]\n",
    "    \n",
    "    # videos \n",
    "    for vid in videos:\n",
    "        # load video\n",
    "        V = asl.video(Df, int(vid))\n",
    "        N = asl.normal_hand(V)\n",
    "        pN = videos[vid]\n",
    "        \n",
    "        # loop\n",
    "        for i in range(len(N)):\n",
    "            if pN[i] != '?':\n",
    "                X.append( N[i].numpy() )\n",
    "                y.append( asl.Encode( pN[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132bb2b5-80e1-46e9-9a47-6f02d36f9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function preprocess at 0x28997bf40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function preprocess at 0x28997bf40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "--- 155.04491806030273 seconds ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     generate_training_data(file)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))   \n\u001b[0;32m----> 9\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray( X )\n\u001b[1;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#training_files = [105143404, 128822441, 33432165, 86446671]\n",
    "training_files = [ 86446671, 33432165 ]\n",
    "import time \n",
    "start_time = time.time()\n",
    "# training_files = [ 86446671 ]\n",
    "for file in training_files:\n",
    "    generate_training_data(file)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57084ae-5c52-4e2e-8fac-86b48fb192c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ba0a5-82b3-43ec-8fb2-6722a39be580",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9535bce1-5f0b-458f-8d61-a87a1c1248f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pause\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "370bc04b-f816-4d76-b074-74c3e8ea421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "k = 59\n",
    "M = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(20, 3)),\n",
    "    tf.keras.layers.Dense(6*k, activation='relu'),\n",
    "    tf.keras.layers.Dense(k)])\n",
    "\n",
    "# Compile Model\n",
    "M.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65f4816-f96a-4643-be63-0fb895bf03e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29a4f2c20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "M.fit( X, y, epochs = 400, verbose=0 )\n",
    "# M.fit( X_train, y_train, epochs = 500, verbose=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96ee1667-c2af-4f70-83cd-b6769c7a1e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373/373 - 1s - loss: 0.5473 - accuracy: 0.8653 - 1s/epoch - 4ms/step\n",
      "accuracy: 0.8653071522712708\n"
     ]
    }
   ],
   "source": [
    "Loss, Acctrain = M.evaluate( X, y, verbose=2)\n",
    "print('accuracy:', Acctrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73f942-0b7d-4ada-9940-d2e5ac910065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss, Acctrain = M.evaluate(X_train, y_train, verbose=2)\n",
    "#Loss, Acctest = M.evaluate(X_test, y_test, verbose=2)\n",
    "#print('\\nTrain accuracy:', Acctrain)\n",
    "#print('\\nTest accuracy:', Acctest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03903124-f656-4974-bc98-723cc4cbd5a5",
   "metadata": {},
   "source": [
    " ### save + load past models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4c429df-a682-477f-a3b3-10be85822346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "# M.save(\"alphabetmodelmain.h5\")\n",
    "\n",
    "# load model \n",
    "# M = tf.keras.models.load_model('asl/alphabetmodel1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd330ab-f64b-4065-9abf-1ddf878db739",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Examples/IMG_0970.MOV'\n",
    "V = asl.video_file(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
